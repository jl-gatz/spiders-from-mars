# Projeto Scraper API

Este projeto tem como objetivo realizar **web scraping de processos e informaÃ§Ãµes pÃºblicas** (inicialmente foi pensado para mapear os processos da Detic/Unicamp ou estruturas similares), organizando os dados coletados de forma estruturada e expondo-os por meio de uma **API REST construÃ­da com FastAPI**.

A arquitetura foi pensada desde o inÃ­cio para permitir:

* EvoluÃ§Ã£o gradual do crawler
* ValidaÃ§Ã£o e padronizaÃ§Ã£o de dados com Pydantic
* Testes e inspeÃ§Ã£o via Swagger
* PossÃ­vel expansÃ£o futura (persistÃªncia, autenticaÃ§Ã£o, filas, etc.)

O projeto combina o espÃ­rito explorador do scraping com a disciplina de uma API moderna. ğŸ•·ï¸â¡ï¸ğŸ“¦

---

## ğŸ§­ VisÃ£o Geral da Arquitetura

```
project_root/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # Ponto de entrada FastAPI
â”‚   â”œâ”€â”€ core/              # ConfiguraÃ§Ãµes globais
â”‚   â”œâ”€â”€ routers/           # Rotas da API (crawler, healthcheck, etc.)
â”‚   â”œâ”€â”€ services/          # LÃ³gica de scraping e processamento
â”‚   â””â”€â”€ utils/             # FunÃ§Ãµes auxiliares
â”‚
â”œâ”€â”€ tests/                 # Testes automatizados
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â””â”€â”€ README.md              # Este arquivo
```

---

## ğŸš€ Tecnologias Utilizadas

* **Python 3.10+**
* **FastAPI** â€“ Framework web moderno e performÃ¡tico
* **Pydantic** â€“ ValidaÃ§Ã£o e serializaÃ§Ã£o de dados
* **Requests / HTTPX** â€“ RequisiÃ§Ãµes HTTP
* **BeautifulSoup / lxml** â€“ Parsing de HTML
* **Uvicorn** â€“ Servidor ASGI

(Dependendo da evoluÃ§Ã£o do projeto, outras bibliotecas como Scrapy, Playwright ou Selenium podem ser incorporadas.)

---

## ğŸ“¦ InstalaÃ§Ã£o (usando Poetry)

Este projeto utiliza **Poetry** para gerenciamento de dependÃªncias e ambientes virtuais, garantindo reprodutibilidade e isolamento.

### PrÃ©-requisitos

* Python **3.10 ou superior**
* Poetry instalado

Caso ainda nÃ£o tenha o Poetry:

```bash
curl -sSL https://install.python-poetry.org | python3 -
```

Ou, se preferir via `pipx`:

```bash
pipx install poetry
```

### Passos de instalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/seu-usuario/spiders-from-mars.git
cd spiders-from-mars
```

2. Configure o Poetry para criar o ambiente virtual no projeto (opcional, mas recomendado):

```bash
poetry config virtualenvs.in-project true
```

3. Instale as dependÃªncias:

```bash
poetry install
```

---

## â–¶ï¸ Executando o Projeto

ApÃ³s a instalaÃ§Ã£o via Poetry, existem duas formas principais de executar a aplicaÃ§Ã£o.

### OpÃ§Ã£o 1: Usando `poetry run`

```bash
poetry run uvicorn app.main:app --reload
```

### OpÃ§Ã£o 2: Ativando o shell do Poetry

```bash
poetry shell
uvicorn app.main:app --reload
```

A API ficarÃ¡ disponÃ­vel em:

* **[http://127.0.0.1:8000](http://127.0.0.1:8000)**
* DocumentaÃ§Ã£o Swagger: **[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)**
* Redoc: **[http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)**

Durante o desenvolvimento, o modo `--reload` reinicia automaticamente o servidor a cada alteraÃ§Ã£o de cÃ³digo.

---

## ğŸ§ª Testando o Crawler

O projeto jÃ¡ inclui um **router dedicado ao crawler**, permitindo testar o scraping diretamente pelo Swagger.

Exemplo de rota:

```
POST /crawler/run
```

Essa rota pode:

* Receber parÃ¢metros como URL alvo, filtros ou identificadores
* Executar o scraping
* Retornar os dados estruturados (JSON)

Sites recomendados para testes iniciais de scraping:

* [https://quotes.toscrape.com](https://quotes.toscrape.com)
* [https://books.toscrape.com](https://books.toscrape.com)

Esses sites sÃ£o feitos especificamente para testes e evitam problemas legais ou Ã©ticos.

---

## ğŸ“ Modelagem de Dados

Os dados coletados sÃ£o validados e serializados usando **Pydantic**, garantindo:

* Tipagem explÃ­cita
* Estruturas previsÃ­veis
* Facilidade de integraÃ§Ã£o futura com banco de dados ou mensageria

Exemplo conceitual:

```python
class Processo(BaseModel):
    numero: str
    titulo: str
    data_publicacao: date
    url_origem: HttpUrl
```

---

## ğŸ”’ Boas PrÃ¡ticas e Ã‰tica

* Respeite o `robots.txt` dos sites
* Evite sobrecarregar servidores
* Use delays e headers adequados
* Scrape apenas dados pÃºblicos e permitidos

Este projeto tem finalidade educacional e experimental.

---

## ğŸ›£ï¸ PrÃ³ximos Passos Planejados

* PersistÃªncia dos dados (PostgreSQL / SQLite)
* ExecuÃ§Ã£o assÃ­ncrona de crawlers
* Agendamento de coletas
* Versionamento de resultados
* AutenticaÃ§Ã£o e controle de acesso
* Logs estruturados e mÃ©tricas

---

## ğŸ§  ObservaÃ§Ã£o Final

Este projeto foi estruturado para crescer sem tropeÃ§ar nos prÃ³prios fios. ComeÃ§a simples, mas jÃ¡ fala a lÃ­ngua de sistemas maiores.

Se o scraper Ã© a aranha, o FastAPI Ã© a teia. ğŸ•¸ï¸

